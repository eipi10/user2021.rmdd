---
title: "Test your code"
subtitle: "Do yourself a favor by taking the right steps"
code: "M13S02C06"
output: 
  formation::chapitre: default
  xaringan::moon_reader: default
prerequis: ["M06-rbase"]
obj_ped: "savoir mettre en place des tests unitaires"
slug: tester-son-code
---
class: slide 

### Automate the testing of your code
 
#### Why automate your code testing?

+ To save time!
+ To work serenely with others.
+ To be able to transfer the project 
+ Guarantee the stability of the project.

#### {testthat} runs at each `check()`.

- Checks that all functions are still doing what they are supposed to do
- {testthat} is integrated with Rstudio and {devtools}
- Tests can be run with `devtools::test()`

---
class: slide 

### Automate the testing of your code

- Initiate a test file for its function: `usethis::use_test("my_function")`
  + Creates a "test/testthat/" folder
  + Adds {testthat} to the `Suggests` of DESCRIPTION
  + Creates "test/testthat.R" (do not touch)
- Create a test file for each function or function family
  + Consistent with function script files in "R/"
  
---
class: slide 

### Automate the testing of your code

Each file is a succession of tests:

```{r eval = FALSE}
test_that("detail serie1", {
  test1a
  test1b	
})

test_that("detail serie2", { 
  test2a
  test2b
})

```

If `test2b` fails, I will be warned that it is the second test of "detail serie2" in "my_function".

---
class: slide 

### Automate the testing of your code

- Your test functions start with `expect_*(object, expected)`.
  + `object` : actual result
  + `expected` : the expected one. 
- If the test fails, the function returns an error. 
- If the test passes, the function returns nothing. 

Several types of tests are possible, including:

```{r eval=TRUE, error=TRUE}
library(testthat)

expect_equal(10, 10)

a <- sample(1:10, 1)
b <- sample(1:10, 1)
expect_equal(a + b, 200)
```


---
class: slide 

### Automate the testing of your code

Exemple of tests available: 

```{r eval = FALSE}
expect_identical()
# Test via identical
expect_error()
expect_message()
expect_warning()
# Test error handling
expect_match()
# Test a string against a regular expression
expect_true()
expect_false()
# Test if the result is true or false 
expect_less_than()
expect_more_than()
# Test if x is greater or less than y 
expect_length()
# Tests the size
```

---
class: slide 

### Automate the testing of your code

#### Exemple of test script in a package:

```{r eval = FALSE}
test_that("test de weighted.mean", {
  expect_equal( weighted.mean(1:10, w = rep(1, 10)), 5.5 )
  expect_equal( weighted.mean(1:10, w = 1:10), 7 )
})

test_that("log fails ", {
  expect_error( log("a") )
  expect_error( log("bonjour") )
})
```

---
exclude: true
class: slide 

### Automate the testing of your code

#### What does this code do?

```{r eval = FALSE}
test_that("test erreur save_as_csv", {
  data(iris)
  expect_error(save_as_csv(iris, "nexiste/pas/out.csv"), "does not exist")
  expect_error(save_as_csv(iris, "fichier.R"), "does not have extension")
})

test_that("test conformite save_as_csv", {
  data(iris)
  expect_is(save_as_csv(iris, "out.csv"), "character")
  expect_true(file.exists(save_as_csv(iris, "out.csv")))
  expect_equal(iris,read.csv2("out.csv"))
})

```

???

Nice...


---
class: slide 

### Automate the testing of your code
 
Launch tests:

```{r eval=FALSE}
devtools::test()
```


```{r, echo=FALSE, out.width="35%"}
knitr::include_graphics("images/exemple_test.png")
```


+ Each line corresponds to a test file

+ Each test is counted as `OK`, `FAIL`, `WARNING`, `SKIP`

+ Each test is launched in its own environment, it is necessary to load the necessary packages and data 

???


To talk a little about {fusen}. In the thumbnail, before sending all the pieces of code to the right place

Separate the function and its roxygen in a chunk named function-1

Separate the usage examples in a chunk named examples-1

Separate the unit tests, with the complete test_that("", {}) structure, in a chunk named tests-1

Indicate that at this point, if this Rmd was in the "dev/" folder, the {fusen} package would move everything to where it needs to be, without anything else to do.

---
class: slide

### Quiz: How to test what is supposed to fail?

- A: `expect_equal()`
- B: `expect_false()`
- C: `expect_error()`
- D: `expect_warning()`

???

- If your function crashes, R returns an Error. 
You can catch it with `expect_error()` to avoid crashing the test script
and check that in this case there is an error.  
It is best if the error is chosen and made explicit in your function with a `stop()` for example

- Depending on your definition of fail, `expect_warning()` can also be a good answer. 
Generally speaking, a warning should be something that the user has to correct in his code. It is good practice to put `stop()` or `message()`, but not `warning()` in your functions.

---
class: slide 
exclude: true

### TD 

**Version A**

Add unit tests to your {tools} package containing the `save_as_csv()` and `clean_names()` functions.

Your package must be documented, **tested** and return 0 errors, 0 warnings, and 0 notes

**Bonus**

Add to your {tools} package, working in a new thumbnail:

+ A function that returns the first 6 values of a chosen column (as a parameter) from a dataset. The output is a vector.
    + `extract_six_from_col(mtcars, "mpg")` works
    + `extract_six_from_col(mtcars, "toto")` returns an error
+ unit tests for `extract_six_from_col()`

Your package must be documented, **tested** and return 0 errors, 0 warnings, and 0 notes

---
class: slide

### Hands-on

- Add unit test in your {hello} package to test that `say_hello()` returns a message
- Check the package

